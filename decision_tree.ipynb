{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier\n",
    "\n",
    "Classification And Regression Tree "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "https://www.youtube.com/watch?v=LDRbO9a6XPU\n",
    "\n",
    "I shamelessly borrowed code from the notebook in the example referenced in the video. https://github.com/random-forests/tutorials/blob/master/decision_tree.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "from collections import Counter\n",
    "from numbers import Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = [\"color\", \"diameter\", \"label\"]\n",
    "label_index = 2\n",
    "data = [\n",
    "    ['Green', 3, 'Apple'],\n",
    "    ['Yellow', 3, 'Apple'],\n",
    "    ['Red', 1, 'Grape'],\n",
    "    ['Green', 1, 'Grape'],\n",
    "    ['Yellow', 3, 'Lemon'],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gini Impurity\n",
    "\n",
    "https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity\n",
    "\n",
    "\"The Gini impurity can be computed by summing the probability p_i of an item with label_i being chosen times the probability of a mistake in categorizing that item. It reaches its minimum (zero) when all cases in the node fall into a single target category.\"\n",
    "\n",
    "-between 0 and 1 where lower values mean less mixing at a node\n",
    "chance of being incorrect if you randomly assign a label to an item in the set\n",
    "\n",
    "-my intuition for this is well mixed (0.5) it contributes a lot to the output. As it becomes more or less present it contributes less and less to the output. As there are more labels there are more contributors to the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(labels):    \n",
    "    impurity = 0\n",
    "    for label, count in Counter(labels).items():\n",
    "        prob_chosen = count / float(len(labels))\n",
    "        impurity += prob_chosen * (1 - prob_chosen)\n",
    "    \n",
    "    return impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini(['a','a','a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini(['a','a','c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini(['a','b','c', 'd', 'e', 'f', 'g', 'h', 'i', 'j'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information gain\n",
    "\n",
    "Used to find the question that reduces uncertainty the most. Describes how much a question helps unmix labels at a node.\n",
    "\n",
    "It is calculated by finding the diff of the impurity before the split and the weighted avg of the impurity in each of the outputs after the split. Weighted avg is used because the size of the split matters (e.g. splitting one item and leaving a group with a lot of impurity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain(labels_in, labels_out_left, labels_out_right):\n",
    "    gini_in = gini(labels_in)\n",
    "    p = len(labels_out_left) / float(len(labels_in))\n",
    "    \n",
    "    return gini(labels_in) - p * gini(labels_out_left) - (1 - p) * gini(labels_out_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_gain(labels_in=['a','b'], labels_out_left=['a'], labels_out_right=['b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_gain(labels_in=['a','b', 'b'], labels_out_left=['a', 'b'], labels_out_right=['b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_gain(labels_in=['a','b', 'b'], labels_out_left=['a', 'b', 'b'], labels_out_right=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define all possible node rules\n",
    "The set of rules is defined from the input data. Try every value for every label.\n",
    "\n",
    "To build every possible rule we split the data for every unique feature value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rule:\n",
    "    def __init__(self, column_name, column_index, column_value):\n",
    "        self.name = column_name\n",
    "        self.index = column_index\n",
    "        self.value = column_value\n",
    "        self.is_numeric = isinstance(column_value, Number)\n",
    "\n",
    "    def match(self, row):\n",
    "        val = row[self.index]\n",
    "        if self.is_numeric:\n",
    "            return val >= self.value\n",
    "        else:\n",
    "            return val == self.value\n",
    "\n",
    "    def __repr__(self):\n",
    "        # This is just a helper method to print\n",
    "        # the question in a readable format.\n",
    "        condition = \"==\"\n",
    "        if self.is_numeric:\n",
    "            condition = \">=\"\n",
    "        return \"Is %s %s %s?\" % (\n",
    "            self.name, condition, str(self.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rule(column_name='color', column_index=0, column_value='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rule(column_name='diameter', column_index=1, column_value=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_rules(header, data, label_index):\n",
    "    rules = []\n",
    "    \n",
    "    for index, name in enumerate(header):\n",
    "        if index != label_index:\n",
    "            # get unique values for index\n",
    "            vals = set()\n",
    "            for row in data:\n",
    "                vals.add(row[index])\n",
    "                \n",
    "            # build a rule for each feature value    \n",
    "            for val in vals:    \n",
    "                rules.append(Rule(name, index, val))\n",
    "            \n",
    "    return set(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = all_rules(header, data, label_index)\n",
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find best split\n",
    "Next define a method that finds the rule that maximizes the information gain. \n",
    "\n",
    "To find the best split, try every rule and pick the one with the highest info gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(data, label_index):\n",
    "    return list(map(lambda row: row[label_index], data))\n",
    "\n",
    "def best_split(data, rules):\n",
    "#     print(\"\\n+++++++++\")\n",
    "#     print(\"input: {}\".format(get_labels(data, label_index)))\n",
    "#     print(\"\\n\")\n",
    "\n",
    "    max_info_gain = 0.\n",
    "    max_rule = None\n",
    "    max_left = None\n",
    "    max_right = None\n",
    "    \n",
    "    for rule in rules:\n",
    "        # for each rule bucket the results into two groups\n",
    "        left = []\n",
    "        right = []\n",
    "        for row in data:\n",
    "            if rule.match(row):\n",
    "                right.append(row)\n",
    "            else:\n",
    "                left.append(row)\n",
    "        \n",
    "        new_info_gain = info_gain(get_labels(data, label_index), get_labels(left, label_index), get_labels(right, label_index))\n",
    "        \n",
    "#         print(\"rule: {}\".format(rule))\n",
    "#         print(\"info_gain: {}\".format(new_info_gain))\n",
    "#         print(\"left: {}\".format(get_labels(left, label_index)))\n",
    "#         print(\"right: {}\".format(get_labels(right, label_index)))\n",
    "#         print(\"\\n\")\n",
    "        \n",
    "        if new_info_gain > max_info_gain:\n",
    "            max_info_gain = new_info_gain\n",
    "            max_rule = rule\n",
    "            max_left = left\n",
    "            max_right = right\n",
    "            \n",
    "#     print(\"max info gain: {}\".format(max_info_gain))\n",
    "#     print(\"max rule: {}\".format(max_rule))\n",
    "#     print(\"max left: {}\".format(max_left))\n",
    "#     print(\"max right: {}\".format(max_right))\n",
    "#     print(\"+++++++++\")        \n",
    "            \n",
    "    return max_info_gain, max_rule, max_left, max_right             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_split(data, rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the full tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,\n",
    "                 rule,\n",
    "                 false_node,\n",
    "                 true_node):\n",
    "        self.rule = rule\n",
    "        self.false_node = false_node\n",
    "        self.true_node = true_node\n",
    "        \n",
    "    def is_leaf(self):\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leaf nodes\n",
    "\n",
    "When a leaf node is reached the decision tree returns the label value for objects end at this leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    def __init__(self, labels):\n",
    "        tot_count = len(labels)\n",
    "        self.predictions = {}\n",
    "        for label, count in Counter(labels).items():\n",
    "            self.predictions[label] = float(count) / tot_count\n",
    "        \n",
    "    def is_leaf(self):\n",
    "        return True   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(header, training_data, label_index):\n",
    "    # create all rules from training data\n",
    "    rules = all_rules(header, training_data, label_index)\n",
    "    \n",
    "    # keep finding best split until cannot be split further\n",
    "    return build_tree_rec(training_data, rules, label_index)\n",
    "    \n",
    "    \n",
    "def build_tree_rec(training_data, rules, label_index):\n",
    "    # base case: impurity is 0 (completely separated)\n",
    "    labels = get_labels(training_data, label_index)\n",
    "    if gini(labels) == 0:\n",
    "        print(\"unmixed: {}\\n\".format(labels))\n",
    "        return Leaf(labels)\n",
    "    \n",
    "    # split data\n",
    "    info_gain, rule, false_data, true_data = best_split(training_data, rules)\n",
    "    \n",
    "    # stop if info gain is 0. that means it can't be split further\n",
    "    if info_gain == 0:\n",
    "        print(\"no more info gain: {}\\n\".format(labels))\n",
    "        return Leaf(labels)\n",
    "    \n",
    "    # build decision tree for each outcome\n",
    "    print(rule)\n",
    "    print(\"new node false: {}\".format(false_data))\n",
    "    print(\"new node true: {}\\n\".format(true_data))\n",
    "    return (Node(\n",
    "        rule, \n",
    "        build_tree_rec(false_data, rules, label_index),\n",
    "        build_tree_rec(true_data, rules, label_index)\n",
    "    ))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = build_tree(header, data, label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node, spacing=\"\"):\n",
    "    \"\"\"World's most elegant tree printing function.\"\"\"\n",
    "\n",
    "    # Base case: we've reached a leaf\n",
    "    if node.is_leaf():\n",
    "        print (spacing + \"Predict\", node.predictions)\n",
    "        return\n",
    "\n",
    "    # Print the question at this node\n",
    "    print (spacing + str(node.rule))\n",
    "\n",
    "    # Call this function recursively on the true branch\n",
    "    print (spacing + '--> True:')\n",
    "    print_tree(node.true_node, spacing + \"  \")\n",
    "\n",
    "    # Call this function recursively on the false branch\n",
    "    print (spacing + '--> False:')\n",
    "    print_tree(node.false_node, spacing + \"  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_tree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(row, node):\n",
    "    \"\"\"See the 'rules of recursion' above.\"\"\"\n",
    "\n",
    "    # Base case: we've reached a leaf\n",
    "    if node.is_leaf():\n",
    "        return node.predictions\n",
    "\n",
    "    # Decide whether to follow the true-branch or the false-branch.\n",
    "    # Compare the feature / value stored in the node,\n",
    "    # to the example we're considering.\n",
    "    if node.rule.match(row):\n",
    "        return classify(row, node.true_node)\n",
    "    else:\n",
    "        return classify(row, node.false_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[0])\n",
    "classify(data[0], tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(['Yellow', 3], tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_depth(tree):\n",
    "    if tree.is_leaf():\n",
    "        return 1\n",
    "    \n",
    "    return 1 + max(tree_depth(tree.false_node), tree_depth(tree.true_node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_depth(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaf_count(tree):\n",
    "    if tree.is_leaf():\n",
    "        return 1\n",
    "    \n",
    "    return leaf_count(tree.false_node) + leaf_count(tree.true_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_count(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature transformations/Normalization\n",
    "\n",
    "Let's try a feature transformation and see if it changes the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = [\"color\", \"diameter\", \"label\"]\n",
    "label_index = 2\n",
    "data = [\n",
    "    ['Green', log(3), 'Apple'],\n",
    "    ['Yellow', log(3), 'Apple'],\n",
    "    ['Red', log(1), 'Grape'],\n",
    "    ['Green', log(1), 'Grape'],\n",
    "    ['Yellow', log(3), 'Lemon'],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_log = build_tree(header, data, label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_tree(tree_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_tree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's the same tree. The absoluate value doesn't make a difference. It is the relative splits within the data that matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
